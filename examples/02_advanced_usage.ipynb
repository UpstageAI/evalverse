{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ðŸŒ  Import Evalverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evalverse version: 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import evalverse as ev\n",
    "\n",
    "evaluator = ev.Evaluator()\n",
    "print(\"evalverse version:\", ev.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ðŸŒ  Check the number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_gpus: 8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"num_gpus:\", num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ðŸŒ  Common Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common args\n",
    "model = \"upstage/SOLAR-10.7B-Instruct-v1.0\"\n",
    "output_path = \"./results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒŒ 1. How to run H6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:104] >> The value of argument \"output_path\" has been changed to \"./results\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:115] >> The value of argument \"h6_en\" has been changed to \"True\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:133] >> Args {'ckpt_path': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'output_path': './results', 'model_name': 'SOLAR-10.7B-Instruct-v1.0', 'use_fast_tokenizer': False, 'devices': '0', 'use_flash_attention_2': False, 'h6_en': True, 'batch_size': 16, 'use_vllm': False, 'gpu_memory_utilization': 0.8, 'model_parallel': 1, 'data_parallel': 1, 'load_in_8bit': False, 'load_in_4bit': False, 'mt_bench': False, 'baselines': None, 'judge_model': 'gpt-4', 'num_gpus_total': 1, 'num_gpus_per_model': 1, 'parallel_api': 1, 'ifeval': False, 'gpu_per_inst_eval': 1, 'eq_bench': False, 'eq_bench_prompt_type': 'ChatML', 'eq_bench_lora_path': None, 'eq_bench_quantization': None}\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:176] >> arc_challenge_25shot done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:176] >> hellaswag_10shot done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:176] >> mmlu_5shot done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:176] >> truthfulqa_mc2_0shot done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:176] >> winogrande_5shot done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:176] >> gsm8k_5shot done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/h6_en/arc_challenge_25.json\n",
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/h6_en/hellaswag_10.json\n",
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/h6_en/mmlu_5.json\n",
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/h6_en/truthfulqa_mc2_0.json\n",
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/h6_en/winogrande_5.json\n",
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/h6_en/gsm8k_5.json\n",
      "ARC-Challenge (25-shot) {\n",
      "    \"acc,none\": 0.6885665529010239,\n",
      "    \"acc_stderr,none\": 0.01353247209985083,\n",
      "    \"acc_norm,none\": 0.7133105802047781,\n",
      "    \"acc_norm_stderr,none\": 0.013214986329274855,\n",
      "    \"alias\": \"arc_challenge\"\n",
      "}\n",
      "Hellaswag (10-shot) {\n",
      "    \"acc,none\": 0.7061342362079267,\n",
      "    \"acc_stderr,none\": 0.004546002255457021,\n",
      "    \"acc_norm,none\": 0.8818960366460864,\n",
      "    \"acc_norm_stderr,none\": 0.0032207161266851005,\n",
      "    \"alias\": \"hellaswag\"\n",
      "}\n",
      "MMLU (5-shot) {\n",
      "    \"acc,none\": 0.655177325167355,\n",
      "    \"acc_stderr,none\": 0.003785654724935679,\n",
      "    \"alias\": \"mmlu\"\n",
      "}\n",
      "TruthfulQA (0-shot) {\n",
      "    \"acc,none\": 0.7171838111166857,\n",
      "    \"acc_stderr,none\": 0.01498853297119472,\n",
      "    \"alias\": \"truthfulqa_mc2\"\n",
      "}\n",
      "Winogrande (5-shot) {\n",
      "    \"acc,none\": 0.8318863456985004,\n",
      "    \"acc_stderr,none\": 0.010510336954166734,\n",
      "    \"alias\": \"winogrande\"\n",
      "}\n",
      "GSM8k (5-shot) {\n",
      "    \"exact_match,strict-match\": 0.6777862016679302,\n",
      "    \"exact_match_stderr,strict-match\": 0.012872435481188778,\n",
      "    \"exact_match,flexible-extract\": 0.6853677028051555,\n",
      "    \"exact_match_stderr,flexible-extract\": 0.012791037227336034,\n",
      "    \"alias\": \"gsm8k\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Arguments for H6\n",
    "benchmark = \"h6_en\"\n",
    "data_parallel = num_gpus # Multi-GPU\n",
    "\n",
    "# Run H6 evaluation\n",
    "evaluator.run(\n",
    "    model=model,\n",
    "    benchmark=benchmark,\n",
    "    output_path=output_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒŒ 2. How to run MT-Bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ðŸŒ  Add OpenAI API Key\n",
    "- `OPENAI_API_KEY` is required to run MT-Bench.\n",
    "\n",
    "- How to add `OPENAI_API_KEY`\n",
    "  - Method 1. `export OPENAI_API_KEY=<Your OpenAI API Key>` in your shell.\n",
    "  - Method 2. Setup with .env file. (Copy from `.env_sample` and rename to `.env`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-...'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check you OpenAI API Key (Warning: Do not commit!)\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ðŸŒ  Run MT-Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:104] >> The value of argument \"output_path\" has been changed to \"./results\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:104] >> The value of argument \"num_gpus_total\" has been changed to \"8\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:104] >> The value of argument \"parallel_api\" has been changed to \"4\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:115] >> The value of argument \"mt_bench\" has been changed to \"True\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:133] >> Args {'ckpt_path': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'output_path': './results', 'model_name': 'SOLAR-10.7B-Instruct-v1.0', 'use_fast_tokenizer': False, 'devices': '0', 'use_flash_attention_2': False, 'h6_en': False, 'batch_size': 16, 'use_vllm': False, 'gpu_memory_utilization': 0.8, 'model_parallel': 1, 'data_parallel': 1, 'load_in_8bit': False, 'load_in_4bit': False, 'mt_bench': True, 'baselines': None, 'judge_model': 'gpt-4', 'num_gpus_total': 8, 'num_gpus_per_model': 1, 'parallel_api': 4, 'ifeval': False, 'gpu_per_inst_eval': 1, 'eq_bench': False, 'eq_bench_prompt_type': 'ChatML', 'eq_bench_lora_path': None, 'eq_bench_quantization': None}\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:201] >> mt_bench done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/mt_bench/scores.txt\n",
      "Mode: single\n",
      "Input file: /data/private/new_lib/evalverse/results/SOLAR-10.7B-Instruct-v1.0/mt_bench/model_judgment/gpt-4_single.jsonl\n",
      "\n",
      "########## First turn ##########\n",
      "                                  score\n",
      "model                     turn         \n",
      "SOLAR-10.7B-Instruct-v1.0 1     7.66875\n",
      "\n",
      "########## Second turn ##########\n",
      "                                  score\n",
      "model                     turn         \n",
      "SOLAR-10.7B-Instruct-v1.0 2     7.21519\n",
      "\n",
      "########## Average ##########\n",
      "                              score\n",
      "model                              \n",
      "SOLAR-10.7B-Instruct-v1.0  7.443396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Arguments for MT-Bench\n",
    "benchmark = \"mt_bench\"\n",
    "num_gpus_total = num_gpus # Multi-GPU\n",
    "parallel_api = 4          # Concurrent API calls\n",
    "\n",
    "# Run MT-Bench evaluation\n",
    "evaluator.run(\n",
    "    model=model,\n",
    "    benchmark=benchmark,\n",
    "    output_path=output_path,\n",
    "    num_gpus_total=num_gpus_total,\n",
    "    parallel_api=parallel_api,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒŒ 3. How to run IFEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:104] >> The value of argument \"output_path\" has been changed to \"./results\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:115] >> The value of argument \"ifeval\" has been changed to \"True\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:133] >> Args {'ckpt_path': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'output_path': './results', 'model_name': 'SOLAR-10.7B-Instruct-v1.0', 'use_fast_tokenizer': False, 'devices': '0', 'use_flash_attention_2': False, 'h6_en': False, 'batch_size': 16, 'use_vllm': False, 'gpu_memory_utilization': 0.8, 'model_parallel': 1, 'data_parallel': 1, 'load_in_8bit': False, 'load_in_4bit': False, 'mt_bench': False, 'baselines': None, 'judge_model': 'gpt-4', 'num_gpus_total': 1, 'num_gpus_per_model': 1, 'parallel_api': 1, 'ifeval': True, 'gpu_per_inst_eval': 1, 'eq_bench': False, 'eq_bench_prompt_type': 'ChatML', 'eq_bench_lora_path': None, 'eq_bench_quantization': None}\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:218] >> ifeval done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/ifeval/scores.txt\n",
      "================================================================\n",
      "/data/private/new_lib/results/SOLAR-10.7B-Instruct-v1.0/ifeval/eval_results_strict.jsonl Accuracy Scores:\n",
      "prompt-level: 0.5157116451016636\n",
      "instruction-level: 0.5796519410977242\n",
      "\n",
      "change_case 0.5595238095238095\n",
      "combination 0.16417910447761194\n",
      "detectable_content 0.8727272727272727\n",
      "detectable_format 0.6666666666666666\n",
      "keywords 0.744\n",
      "language 0.8\n",
      "length_constraints 0.5631067961165048\n",
      "punctuation 0.1791044776119403\n",
      "startend 0.6060606060606061\n",
      "\n",
      "change_case:capital_word_frequency 0.7\n",
      "change_case:english_capital 0.4230769230769231\n",
      "change_case:english_lowercase 0.5789473684210527\n",
      "combination:repeat_prompt 0.047619047619047616\n",
      "combination:two_responses 0.36\n",
      "detectable_content:number_placeholders 0.8076923076923077\n",
      "detectable_content:postscript 0.9310344827586207\n",
      "detectable_format:constrained_response 0.9\n",
      "detectable_format:json_format 0.7647058823529411\n",
      "detectable_format:multiple_sections 0.25\n",
      "detectable_format:number_bullet_lists 0.46153846153846156\n",
      "detectable_format:number_highlighted_sections 0.5714285714285714\n",
      "detectable_format:title 0.9722222222222222\n",
      "keywords:existence 0.9523809523809523\n",
      "keywords:forbidden_words 0.5833333333333334\n",
      "keywords:frequency 0.8461538461538461\n",
      "keywords:letter_frequency 0.6551724137931034\n",
      "language:response_language 0.8\n",
      "length_constraints:nth_paragraph_first_word 0.16666666666666666\n",
      "length_constraints:number_paragraphs 0.4\n",
      "length_constraints:number_sentences 0.6666666666666666\n",
      "length_constraints:number_words 0.7333333333333333\n",
      "punctuation:no_comma 0.1791044776119403\n",
      "startend:end_checker 0.72\n",
      "startend:quotation 0.5365853658536586\n",
      "================================================================\n",
      "/data/private/new_lib/results/SOLAR-10.7B-Instruct-v1.0/ifeval/eval_results_loose.jsonl Accuracy Scores:\n",
      "prompt-level: 0.5600739371534196\n",
      "instruction-level: 0.6291834002677377\n",
      "\n",
      "change_case 0.6071428571428571\n",
      "combination 0.16417910447761194\n",
      "detectable_content 0.8727272727272727\n",
      "detectable_format 0.68\n",
      "keywords 0.832\n",
      "language 0.8666666666666667\n",
      "length_constraints 0.6213592233009708\n",
      "punctuation 0.31343283582089554\n",
      "startend 0.6515151515151515\n",
      "\n",
      "change_case:capital_word_frequency 0.75\n",
      "change_case:english_capital 0.5\n",
      "change_case:english_lowercase 0.6052631578947368\n",
      "combination:repeat_prompt 0.047619047619047616\n",
      "combination:two_responses 0.36\n",
      "detectable_content:number_placeholders 0.8076923076923077\n",
      "detectable_content:postscript 0.9310344827586207\n",
      "detectable_format:constrained_response 0.9\n",
      "detectable_format:json_format 0.8823529411764706\n",
      "detectable_format:multiple_sections 0.25\n",
      "detectable_format:number_bullet_lists 0.46153846153846156\n",
      "detectable_format:number_highlighted_sections 0.5714285714285714\n",
      "detectable_format:title 0.9722222222222222\n",
      "keywords:existence 0.9523809523809523\n",
      "keywords:forbidden_words 0.8333333333333334\n",
      "keywords:frequency 0.8974358974358975\n",
      "keywords:letter_frequency 0.6551724137931034\n",
      "language:response_language 0.8666666666666667\n",
      "length_constraints:nth_paragraph_first_word 0.5\n",
      "length_constraints:number_paragraphs 0.44\n",
      "length_constraints:number_sentences 0.6666666666666666\n",
      "length_constraints:number_words 0.7666666666666667\n",
      "punctuation:no_comma 0.31343283582089554\n",
      "startend:end_checker 0.72\n",
      "startend:quotation 0.6097560975609756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Arguments for IFEval\n",
    "benchmark = \"ifeval\"\n",
    "\n",
    "# Run IFEval evaluation\n",
    "evaluator.run(\n",
    "    model=model,\n",
    "    benchmark=benchmark,\n",
    "    output_path=output_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒŒ 4. How to run EQ-Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:104] >> The value of argument \"output_path\" has been changed to \"./results\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:115] >> The value of argument \"eq_bench\" has been changed to \"True\".\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:133] >> Args {'ckpt_path': 'upstage/SOLAR-10.7B-Instruct-v1.0', 'output_path': './results', 'model_name': 'SOLAR-10.7B-Instruct-v1.0', 'use_fast_tokenizer': False, 'devices': '0', 'use_flash_attention_2': False, 'h6_en': False, 'batch_size': 16, 'use_vllm': False, 'gpu_memory_utilization': 0.8, 'model_parallel': 1, 'data_parallel': 1, 'load_in_8bit': False, 'load_in_4bit': False, 'mt_bench': False, 'baselines': None, 'judge_model': 'gpt-4', 'num_gpus_total': 1, 'num_gpus_per_model': 1, 'parallel_api': 1, 'ifeval': False, 'gpu_per_inst_eval': 1, 'eq_bench': True, 'eq_bench_prompt_type': 'ChatML', 'eq_bench_lora_path': None, 'eq_bench_quantization': None}\n",
      "[2024-04-02 16:14:18][INFO][evalverse - evaluator.py:239] >> eq_bench done! exec_time: 0 min for upstage/SOLAR-10.7B-Instruct-v1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result already exists: /data/private/new_lib/evalverse/examples/results/SOLAR-10.7B-Instruct-v1.0/eq_bench/raw_results.json\n",
      "{\n",
      "    \"first_pass_score\": 70.06006445118443,\n",
      "    \"first_pass_parseable\": 169,\n",
      "    \"revised_score\": 0,\n",
      "    \"revised_parseable\": 0,\n",
      "    \"final_score\": 70.06006445118443,\n",
      "    \"final_parseable\": 169\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Arguments for EQ-Bench\n",
    "benchmark = \"eq_bench\"\n",
    "\n",
    "# Run EQ-Bench evaluation\n",
    "evaluator.run(\n",
    "    model=model,\n",
    "    benchmark=benchmark,\n",
    "    output_path=output_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŒŒ 5. How to run all benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments for EQ-Bench\n",
    "benchmark = \"all\" # is same with [\"h6_en\", \"mt_bench\", \"ifeval\", \"eq_bench\"]\n",
    "\n",
    "# Run EQ-Bench evaluation\n",
    "evaluator.run(\n",
    "    model=model,\n",
    "    benchmark=benchmark,\n",
    "    output_path=output_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evalverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
